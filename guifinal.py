from tkinter import *
from tkinter import filedialog
import tkinter as tk
import numpy as np
import matplotlib.pyplot as plt
import h5py
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from keras import backend as K
from keras.models import load_model 
from keras.utils.vis_utils import plot_model
from keras.preprocessing.image import ImageDataGenerator
import cv2
import os
from sklearn.model_selection import train_test_split
from tkinter import messagebox
K.set_image_data_format('channels_last')

model=1
path="img.png"
# GUI Setup
window = tk.Tk()
window.title("Breast Cancer Detection using Deep Learning")


screen_width = window.winfo_screenwidth()
screen_height = window.winfo_screenheight()
window_width = 1200
window_height = 700
center_x = int(screen_width/2 - window_width/2)
center_y = int(screen_height/2 - window_height/2)

window.geometry(f'{window_width}x{window_height}+{center_x}+{center_y}')

# load data
numepochs=5
batchsize=128
folder_path = './data/'
images = []
labels = []
class_label = 0

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

def load_images_from_folder(folder,class_label):
	for filename in os.listdir(folder):
		img = cv2.imread(os.path.join(folder, filename))
		if img is not None:
			img = cv2.resize(img,(140,92))
			img = img.reshape(92,140,3)
			images.append(img)
			labels.append(class_label)
	class_label=class_label+1
	return class_label


# define the larger model
def larger_model():
	# create model
	model = Sequential()
	model.add(Conv2D(32, (3, 3), padding="same",input_shape=(92,140,3), activation='relu'))
	#model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
	#model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
	#model.add(Conv2D(128, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.5))
	model.add(Flatten())
	model.add(Dropout(0.5))
	model.add(Dense(64, activation='relu'))
	model.add(Dropout(0.5))
	model.add(Dense(64, activation='relu'))
	model.add(Dropout(0.5))
	#model.add(Dense(50, activation='relu'))
	#model.add(Dropout(0.2))
	model.add(Dense(2, activation='softmax'))
	# Compile model
	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
	return model


class_label = 0
class_label = load_images_from_folder(folder_path+'benign',class_label)
class_label = load_images_from_folder(folder_path+'malignant',class_label)

Data = np.asarray(images)
Labels = np.asarray(labels)

X_train,X_test,y_train,y_test=train_test_split(Data,Labels,test_size=0.2,random_state=2)

# normalize inputs from 0-255 to 0-1
X_train = X_train / 255
X_test = X_test / 255
# one hot encode outputs
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

tr="train data shape:"+"\n"
tr=tr+"test data shape:"+"\n"
tr=tr+str(X_test.shape)+"\n"
tr=tr+"train label shape:"+"\n"
tr=tr+str(y_train.shape)+"\n"
tr=tr+"test label shape:"+"\n"
tr=tr+str(y_test.shape)+"\n"

def training(X_train, y_train, X_test, y_test, tr):
    global hist, model
    model = larger_model()
    
    # Fit the augmentation to our training data
    datagen.fit(X_train)
    
    # Train the model on the batches generated by datagen.flow()
    hist = model.fit(
        datagen.flow(X_train, y_train, batch_size=batchsize),
        steps_per_epoch=len(X_train) // batchsize,
        epochs=numepochs,
        validation_data=(X_test, y_test))
    
    model.summary()
    scores = model.evaluate(X_test, y_test, verbose=1, batch_size=batchsize)
    model.save('28april.h5')
    print(f"Deep Net Accuracy: {scores[1]*100:.2f}%")
    
    greetings_disp = tk.Text(master=window, height=20, width=120, fg="white")
    greetings_disp.grid(column=0, row=3)
    ly = ""
    for layer in model.layers:
        ly += f"{layer.name}        layer input: {layer.input}\n"
    greetings_disp.insert(tk.END, f"<<--LAYER ARCHITECTURE-->>\n\n{ly}\n\nNETWORK is trained with Accuracy of {scores[1]*100:.2f}%")
    return model
